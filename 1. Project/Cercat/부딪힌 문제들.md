
> [!tip]+ 유저정보 캐싱
> 유저정보를 캐싱할때 저장하는 로직에서 캐싱한 유저정보로 save하게되면 영속성 컨텍스트에 유저정보가 없기때문에 오류발생 저장로직에서는 캐싱힌 유저정보를 사용하지말자


> [!faq]+ 알림을 폴링으로 구현할 것인가?
> 알림을 폴링으로 구현할 경우 알림이 없다면 클라이언트에서 붎필요한 요청을 주기적으로 보내게되고
> 사용자가 증가했을시 서버 성능에 영향을 미칠수 있다고 판단. SSE로 알림을 구현하는것으로 결정


> [!question]+ 서비스간의 순환 참조를 어떻게 해결할 것인가?
> 난 JPA의 단일 fetch때마다 orElseThrow로 예외처리해주는게 계속반복되는게 싫었기때문에
> 해당 엔티티 서비스에 에러처리까지하는 fetch메서드를 작성하고 그 엔티티가 필요할때마다 그 서비스의
> 메서드를 호출하여 코드를 짜고있었는데 이 경우 서로의 서비스가 서로의 엔티티가 필요하여 참조할 경우
> 순환 참조가 발생하게됐고 이걸 어떻게 해결하면 좋을까 고민을 정말 많이였고 고민 끝에 도입한것이 
> facade패턴이다. 
> 
> 각 엔티티의 서비스에서는 가져오거나 생성하여 insert하는 간단한 로직만 처리하고 
> 복잡한 비즈니스로직은 facade에서 처리하는것이다. 다만 이렇게 할 경우 facade가 굉장히 무거워질수도
> 있기때문에 create, fatch, update, delete로 나누어서 설계하였다.


> [!faq]+ 좋아요 기능의 동시성 문제를 어떻게 해결할것인가?
> 게시글의 좋아요 갯수는 정말 많이 호출되는 API이다. 이 서비스에서 좋아요 테이블을 분리하여 설계하였기때문에 좋아요 갯수를 가져오기위해선 JOIN을 해서 가져와야했다. 
> 
> 하지만 게시글 상세에 들어갈때마다 호출되는API인데 이런식으로 항상 JOIN을 해서 가져오면 성능상의 문제가 있다고 판단하여 비정규화를 하여 좋아요 갯수를 POST 테이블에도 추가하였다. 
> 
> 좋아요를 누르면 좋아요 엔티티도 생성되고 게시글의 좋아요 갯수도 업데이트되는 트랜잭션이다. 
> 
> 하지만 여기서 바로 동시성 문제가 발생한다. 동시에 다른사용자가 좋아요를 눌렀을 경우 동시성 문제가 발생하고 이 경우 게시글의 좋아요 개수와 좋아요 엔티티 갯수가 맞지 않게 되는 데이터 정합성 문제가 생긴다. 
> 
> 이를 막기위해 다소 성능에 문제가 생길수있지만 좋아요 갯수 증가를 위한 게시글 select 요청에서 비관적 락을 통해 동시성 문제를 해결하였다.


> [!faq]+ 좋아요 기능의 중복되는 코드
> 전략 패턴을 도입하여 확장에는 열려있지만 좀 억지로 도입한 감이 없지 않아있다.
> 좋아요기능은 확장할 일이 거의 없기도 하고, 전략패턴이 정말 필요한 시기는 알고리즘 전략이 여러개 있고,
> 런타임에 이 알고리즘 전략을 동적으로 변경해주기위한 패턴이지만 지금 나의 문제는 코드의 중복이었다. 
> 즉, 거의 비슷한 알고리즘군을 전략패턴으로 나누었기때문에 올바른 쓰임은 아닌거같다.
> 
> 이번에는 제네릭을 사용해서 요상하게 구현했지만 올바른 구현방법은 메서드의 엔티티 매개변수가 있고 
> 이 엔티티의 상태에 따라 알고리즘 전략이 바뀔 때 사용하면 깔끔하게 사용할 수 있을것 같다.
> 
> _LikeFlipService_



> [!bug]+ Swagger를 통한 API 문서화시에 JWT 인증 토큰설정이 웹 새로고침시마다 날라가는 문제
> application.yml
> ```json
> springdoc:  
>   swagger-ui:  
>     persist-authorization: true
> ```
> 설정으로 해결

> [!tip]+ 리프레쉬 토큰 탈취에 대비해 RTR 방법을 적용
> 리프레쉬 토큰을 1회용으로 사용

> [!NOTE]- Json으로 Paging요청시 예시
> ```json
> {
  "page": 0,
  "size": 10,
  "sort": [ 
  "LikeCount,DESC"
  ]
  }
> ```

> [!warning]+ 모의고사 성적 총점을 가져올때 쿼리 문제
> 난 DB를 설계할때 최대한 중복되는 컬럼이 없도록 설계하였다 하지만 이렇게 설계하니
> 단순히 모의고사 성적 총점을 가져와야하는 쿼리에서도 복잡한 JOIN과 Subquery를 사용하게되었다.
> (나로써는 다른 좋은 방법은 찾지 못했다...) 
> 
> 내가 보는 기술블로그에 쿼리에서 subquery는 안티패턴이락 말하기도 했고 성적 리포트 통계를 구현할때
> 모의고사 총점을 select해야할 일이 정말 많은데 그때마다 복잡한 쿼리를 날리는게 쿼리짜기도 어렵고 성능상에도 문제가 있을것으로 예상되었다. 
> 
> 따라서 나는 어느정도에 비정규화는 때로는 성능과 가독성, 구현면에서 
> 모두 이득이 되기도한다는 깨달음을 얻엇고 기존 subjectResult의 score들을 모두 더하여 구했던 모의고사 총점을 mockExamResult 테이블에 컬럼으로 넣었다.
> 
> 이렇게 비정규화를 함으로써 구현도 간단해지고 쿼리도 훨씬 간단해졌다.


> [!warning] Batch 서버의 코드 중복
> 자격증 시험알림 batch 작업을 위해 batch서버를 따로만들어주어야했다. 
> batch 프로젝트를 새로 만들어 서버를 만들었지만 cercat서버와 batch서버의 중복되는 코드가
> 굉장히 많았고 batch서버 또는 cercat서버의 알림에서 수정이 발생하면 다른쪽도 수정해야했기에
> 유지보수가 어려웠다
> 
> 이 문제를 해결하기위해선 멀티 모듈을 적용하면 될것으로 보인다.
> 멀티 모듈을 적용하게되면 중복되는 코드는 줄고 각각의 모듈이 독립적인 역할을 하여 의존성이 줄어든다.


> [!bug] JPA delete 쿼리가 날라가지 않는 문제
>댓글을 삭제하려고 할때 댓글 엔티티를 조회하는데 이때 fetchType이 eager인 post를 가져오면서 post에서 또 eager로 되어있는 post comments들을 가져온다. 
>
>이때 post comment를 delete를 하게됐을 때 영속성 컨텍스트 내의 post의 post comments들과 동기화가 되지않아 삭제 쿼리가 날라가지 않는 오류 해결
>
>결론 : 사이드 이펙트가 나지않게 FetchType을 막 설정하지 말자...


> [!warn] Debezium mysql delete후에 kafka message가 2개 날라가는 이유
> A tombstone record that has the same key as the deleted row and a value of `null`. 
> 
> This record is a marker for Apache Kafka. 
> It indicates that [log compaction](https://kafka.apache.org/documentation/#compaction) can remove all records that have this key.
> 
> 아래 설정으로 해결할 수 있다.
```js
curl --location --request POST 'http://localhost:8083/connectors' --header 'Content-Type: application/json' --data-raw '{
  "name": "debezium-connector-mysql",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "database.hostname": "host.docker.internal",
    "database.port": "3306",
    "database.user": "mysqluser",
    "database.password": "mysqlpw",
    "database.include.list": "cercat",
    "table.include.list": "cercat.post, cercat.post_comment",
    "database.server.id": "184054",
    "database.server.name": "mysqlcdc",
    "topic.prefix" : "cercat",
    "database.history.kafka.bootstrap.servers": "kafka:9092",
    "database.history.kafka.topic": "dbhistory.mysqlcdc",
    "include.schema.changes": "true",
    "database.ssl.mode": "disabled",
    "database.allowPublicKeyRetrieval": "true",
    "transforms": "addTopicPrefix",
    "transforms.addTopicPrefix.type":"org.apache.kafka.connect.transforms.RegexRouter",
    "transforms.addTopicPrefix.regex":"(.*)",
    "transforms.addTopicPrefix.replacement":"$1",
    "schema.history.internal.kafka.topic": "schemahistory.fullfillment",
    "schema.history.internal.kafka.bootstrap.servers": "kafka:9092", "tombstones.on.delete": "false" 
  }
}'
```


> [!faq] 게시글 조회 시 좋아요 여부 확인 방법에 대해
> 두가지 방법을 생각
>1. exitst로 조회
>2. 양방향 매핑으로 post및 comment가 좋아요를 가지고있고 각 엔티티 내에서 contain함수로 확인
>
>난 첫번째 방법을 사용, exist이기때문에 성능상 이점이 있다고 판단
>2번째 방법은 좋아요 갯수가 많아질수록 성능이 안좋아짐


> [!NOTE]+ host.docker.internal
> Mac에서 Docker 사용시에 host.docker.internal 사용시에는 host머신의 IP를 자동으로 가져오지만
> Linux에서는 아쉽게도 작동하지않는다.
> 
> Linux에서 host.docker.internal을 사용하려면 docker-compose.yml 파일에 
> 다음과 같이 설정해주어야한다.
```js
version: "3.8"

services:
  cercat:
    container_name: cercat
    extra_hosts:
      - "host.docker.internal:host-gateway"
```


> [!danger] Elastic search docker 볼륨 설정 오류
> 
> ```
> sudo chown -R 1000:0 elastic-search/data/
> ```
> 로 마운트된 디렉토리에 권한 부여

> [!danger] Elastic search docker 메모리 문제
> docker compose에서 mem-limits 설정



> [!warn] batch 서버 웹서버 기동 끄는법
> batch서버는 실행되고 종료되어야하는데 web에 의존성이 생겨서 웹서버가 떠 계속 서버가 떠있게된다.
> 이때 아래와 같은 yml 설정을 해주면 웹서버 가동을 끌 수 있다.
```js
spring
	main:  
		web-application-type: none
```



> [!question] 비즈니스 로직과 구현 로직의 구분
> 내가 정의한 비즈니스로직 
> - 어떤 유스케이스를 구현하는 일련의 과정(로직)이고 이 일련의 과정속에 프로그램이 무슨일을 하는지는 중요하지않음.
> 
> - 이 일련의 과정을 수행하기위해 내부적으로 수행하는 로직이 구현 로직



> [!question] 엔티티 및 도메인의 연관관계
> 
> 
> 이부분이 너무 어렵다.
> 재민님은 생명주기가 일치하면 그때 연관관계를 고려하라고 했지만 생명주기라는 개념이 잘안와닿기도하고 특정 문제에 대한 해설 게시글은 생명주기가 일치하는건가?(일치하는거같음)
> 
> - 생명주기가 일치한다면 도메인이 제안하는 Interface를 구현한 Storage영역에서 두 엔티티의 JPARepository를 의존해도됨
> - 생명주기가 일치하지않는다면 구현레이어에서 Reader를 통해 조합?
>   
>  나의 원칙을 정하여 해결->
>  - 생명주기가 일치
>  - 테이블이 연관관계를 맺고있음
>  - 같은 개념
>  - 도메인의 내용이 비즈니스 레이어에서 필요하다면 조회, 아니라면 분리된 개념모델을 파라미터로 내림
>    
>  "위의 3가지 원칙을 지키면서 도메인 레파지토리의 의존성을 구성"
>  
>  위 원칙을 만족하지않는 도메인을 함께조회하려면 구현레이어(비즈니스? 이건 잘모르겠음)에서 조합



> [!bug] 도메인 모듈을 분리했을 때연관관계를 가지는 엔티티 저장할때 이슈
> - 기존 연관관계에 있는 도메인의 레파지토리에 의존하여 getRefence로 프록시객체를 통해 save를 진행했었지만 의존을 없애고 도메인 -> 엔티티 변환을 통해 save
>   
save를 할때에는 session에 해당 연관관계 객체가 없어도 된다는것을 알았다.


